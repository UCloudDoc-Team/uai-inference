{{indexmenu_n>7}}

====== 常见问题Q&A ======

=== 1. 我的请求延时分布不显示 ===
  * 请求延时分布的最小粒度为小时，因此请在**监控信息**的监控间隙选择6小时以上。

=== 2. 我的服务部署后无法请求 ===
您可以查询实时日志查看节点的运行日志，常见的无法请求可能有如下原因：
  * 模型加载失败，请在本地测试在AI Inference平台部署的Docker 容器的正确性。
  * 模型加载缓慢，nvidia 的nvcc编译在编译代码时需要选择目标GPU平台（Tesla、Pascal、Volta等）以直接编译成静态优化的代码，否则将仅编译ptx中间代码然后在具体执行时由系统实时编译（例如编译代码时仅选择了Tesla平台，但是代码在Pascal平台执行，系统在执行GPU代码钱会进行编译操作），该编译操作相当耗时，因此会导致容器长时间无法服务。